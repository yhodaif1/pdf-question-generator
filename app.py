import os
import streamlit as st
from PyPDF2 import PdfReader
import requests

# This MUST be the first Streamlit command
st.set_page_config(
    page_title="ูููุฏ ุงูุฃุณุฆูุฉ ูู PDF",
    page_icon="๐",
    layout="wide"
)

# ูุฑุงุกุฉ ุฑูุฒ API ูู secrets ุฃู ูุชุบูุฑ ุงูุจูุฆุฉ
API_TOKEN = st.secrets.get("API_TOKEN") or os.getenv("API_TOKEN")

# ุฅุฐุง ูู ููุฌุฏุ ุงุทูุจู ูู ุงููุณุชุฎุฏู
if not API_TOKEN:
    st.warning("โ๏ธ ูู ูุชู ุงูุนุซูุฑ ุนูู API Token ูู ุฅุนุฏุงุฏุงุช ุงูุชุทุจูู")
    API_TOKEN = st.text_input(
        "ุฃุฏุฎู Hugging Face API Token:", 
        type="password",
        help="ุงุญุตู ุนูู ุงูู Token ูู huggingface.co/settings/tokens"
    )
    
    if not API_TOKEN:
        st.info("๐ก ููููู ุงูุญุตูู ุนูู Token ูุฌุงูู ูู: https://huggingface.co/settings/tokens")
        st.stop()

# ุงูููุงุฐุฌ ุงูุนุฑุจูุฉ ุงููุชุงุญุฉ ูู Inference API
ARABIC_MODELS = {
    "microsoft/DialoGPT-medium": "DialoGPT Medium - ูููุฐุฌ ุงููุญุงุฏุซุฉ",
    "gpt2": "GPT-2 - ูููุฐุฌ ุชูููุฏ ุงููุตูุต (ูุฏุนู ุงูุนุฑุจูุฉ)",
    "facebook/blenderbot-400M-distill": "BlenderBot - ูููุฐุฌ ูุญุงุฏุซุฉ ุฐูู",
    "microsoft/DialoGPT-small": "DialoGPT Small - ูููุฐุฌ ูุญุงุฏุซุฉ ูุจุณุท"
}

# ุฏุงูุฉ ูุงุณุชุฏุนุงุก API ุชูููุฏ ุงูุฃุณุฆูุฉ ูู Hugging Face
def generate_questions(text, api_token, question_types, selected_model):
    headers = {"Authorization": f"Bearer {api_token}"}
    
    # ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงููุฎุชุงุฑ
    api_url = f"https://api-inference.huggingface.co/models/{selected_model}"
    
    # ุชุญุถูุฑ ุงููุต ูููููุฐุฌ (ุชุจุณูุท ุงูู prompt)
    prompt = f"ุฃูุดุฆ ุฃุณุฆูุฉ ูู ุงููุต ุงูุชุงูู:\n\n{text[:1000]}\n\nุงูุฃุณุฆูุฉ:"
    
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 500,
            "temperature": 0.7,
            "do_sample": True,
            "return_full_text": False
        }
    }
    
    try:
        response = requests.post(api_url, headers=headers, json=payload, timeout=60)
        if response.status_code == 200:
            return response.json()
        else:
            return {"error": f"API request failed with status {response.status_code}: {response.text}"}
    except requests.exceptions.RequestException as e:
        return {"error": f"Request failed: {str(e)}"}

# ุฏุงูุฉ ูุชูููุฏ ุฃุณุฆูุฉ ุงูุชุฑุงุถูุฉ ูุญุณูุฉ
def generate_default_questions(text, question_types):
    # ุงุณุชุฎุฑุงุฌ ุงูุนููุงู ุงููุญุชูู ูู ุงููุต
    lines = text.split('\n')
    topic = "ุงููุญุชูู ุงููุณุชุฎุฑุฌ"
    
    # ุงูุจุญุซ ุนู ุนููุงู ููุงุณุจ
    for line in lines[:10]:
        if line.strip() and len(line.strip()) > 5 and len(line.strip()) < 100:
            # ุชุฌูุจ ุงูุฃุฑูุงู ูุงูุฑููุฒ
            if not line.strip().isdigit() and not line.strip().startswith('---'):
                topic = line.strip()[:60]
                break
    
    # ุงุณุชุฎุฑุงุฌ ุงููููุงุช ุงูููุชุงุญูุฉ
    words = text.replace('\n', ' ').split()
    keywords = []
    for word in words[:50]:  # ุฃูู 50 ูููุฉ
        if len(word) > 3 and word.isalpha():
            keywords.append(word)
    
    # ููุฎุต ูุตูุฑ
    sentences = text.split('.')
    summary = ""
    for sentence in sentences[:3]:
        if len(sentence.strip()) > 10:
            summary += sentence.strip() + ". "
    
    if not summary:
        summary = text[:150].replace('\n', ' ').strip() + "..."
    
    # ุจูุงุก ุงูุฃุณุฆูุฉ ุงูููุธูุฉ
    questions_structure = f"""
ุงูููุถูุน: {topic}
ุงูููุฎุต: {summary}

ุงูุฃุณุฆูุฉ ุงููููุฏุฉ:
========================
"""
    
    question_count = 1
    
    # ุฅุถุงูุฉ ุฃุณุฆูุฉ ุญุณุจ ุงูููุน ุงููุฎุชุงุฑ
    if "ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ" in question_types:
        questions_structure += f"""
{question_count}. ุงูููุน: ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ
   ุงูุณุคุงู: ูุง ูู ุงูููุถูุน ุงูุฑุฆูุณู ุงููุชูุงูู ูู ุงููุตุ
   ุงูุฎูุงุฑุงุช:
   ุฃ) {keywords[0] if len(keywords) > 0 else 'ุงูุฎูุงุฑ ุงูุฃูู'}
   ุจ) {keywords[1] if len(keywords) > 1 else 'ุงูุฎูุงุฑ ุงูุซุงูู'}
   ุฌ) {keywords[2] if len(keywords) > 2 else 'ุงูุฎูุงุฑ ุงูุซุงูุซ'}
   ุฏ) ุฌููุน ูุง ุณุจู
   ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ: ุฏ

"""
        question_count += 1
    
    if "ุตุญ ุฃู ุฎุทุฃ" in question_types:
        questions_structure += f"""
{question_count}. ุงูููุน: ุตุญ ุฃู ุฎุทุฃ
   ุงูุณุคุงู: ุงููุต ูุญุชูู ุนูู ูุนูููุงุช ุชูุตูููุฉ ููููุฏุฉ ุญูู ุงูููุถูุน
   ุงูุฅุฌุงุจุฉ: ุตุญูุญ
   ุงูุชุจุฑูุฑ: ุงููุต ููุฏู ูุนูููุงุช ุดุงููุฉ ูููุตูุฉ

"""
        question_count += 1
    
    if "ูุทุงุจูุฉ" in question_types:
        questions_structure += f"""
{question_count}. ุงูููุน: ูุทุงุจูุฉ
   ุงุฑุจุท ุจูู ุงููุตุทูุญุงุช ูุงูุชุนุฑููุงุช:
   ุงููุตุทูุญุงุช: {', '.join(keywords[:3]) if len(keywords) >= 3 else 'ุงููุตุทูุญ ุงูุฃููุ ุงููุตุทูุญ ุงูุซุงููุ ุงููุตุทูุญ ุงูุซุงูุซ'}
   ุงูุชุนุฑููุงุช: [ุชุนุฑูู ููุตู ููู ูุตุทูุญ ุจูุงุกู ุนูู ุงูุณูุงู]

"""
        question_count += 1
    
    if "ูููุงุช ูุชูุงุทุนุฉ" in question_types:
        questions_structure += f"""
{question_count}. ุงูููุน: ูููุงุช ูุชูุงุทุนุฉ
   ุดุจูุฉ ุงููููุงุช ุงููุชูุงุทุนุฉ: [ุดุจูุฉ 7ร7]
   ุงููููุงุช ุงููุณุชุฎุฏูุฉ: {', '.join(keywords[:5]) if len(keywords) >= 5 else 'ูููุงุช ููุชุงุญูุฉ ูู ุงููุต'}
   
   ุงูุชุนุฑููุงุช:
   ุฃูููุงู:
   - 1. {keywords[0] if len(keywords) > 0 else 'ูุตุทูุญ ูู ุงููุต'} (4 ุฃุญุฑู)
   - 3. {keywords[1] if len(keywords) > 1 else 'ููููู ููู'} (6 ุฃุญุฑู)
   
   ุนููุฏูุงู:
   - 2. {keywords[2] if len(keywords) > 2 else 'ูููุฉ ุฑุฆูุณูุฉ'} (5 ุฃุญุฑู)
   - 4. {keywords[3] if len(keywords) > 3 else 'ููุถูุน ูุฑุนู'} (7 ุฃุญุฑู)

"""
    
    # ุฅุถุงูุฉ ูุนูููุงุช ุฅุถุงููุฉ
    questions_structure += f"""
========================
ูุนูููุงุช ุฅุถุงููุฉ:
- ุนุฏุฏ ุงููููุงุช ูู ุงููุต: {len(text.split())}
- ุนุฏุฏ ุงูุฃุญุฑู: {len(text)}
- ุงููููุงุช ุงูููุชุงุญูุฉ ุงููุณุชุฎุฑุฌุฉ: {', '.join(keywords[:10])}
- ุชุงุฑูุฎ ุงูุฅูุดุงุก: {st.session_state.get('generation_time', 'ุบูุฑ ูุญุฏุฏ')}
"""
    
    return questions_structure

# ุฏุงูุฉ ูุงุณุชุฎุฑุงุฌ ุงููุต ูู ูุทุงู ุตูุญุงุช ูุญุฏุฏ
def extract_text_from_pages(pdf_file, start_page, end_page):
    full_text = ""
    try:
        pdf = PdfReader(pdf_file)
        total_pages = len(pdf.pages)
        
        # ุงูุชุฃูุฏ ูู ุตุญุฉ ูุทุงู ุงูุตูุญุงุช
        start_page = max(1, min(start_page, total_pages))
        end_page = max(start_page, min(end_page, total_pages))
        
        # ุงุณุชุฎุฑุงุฌ ุงููุต ูู ุงูุตูุญุงุช ุงููุญุฏุฏุฉ
        for page_num in range(start_page - 1, end_page):
            page = pdf.pages[page_num]
            text = page.extract_text()
            if text:
                full_text += f"--- ุตูุญุฉ {page_num + 1} ---\n{text}\n\n"
        
        return full_text, total_pages, None
    except Exception as e:
        return "", 0, str(e)

# ุฏุงูุฉ ููุชุญูู ูู ุญุงูุฉ ุงููููุฐุฌ
def check_model_status(model_name, api_token):
    headers = {"Authorization": f"Bearer {api_token}"}
    api_url = f"https://api-inference.huggingface.co/models/{model_name}"
    
    try:
        response = requests.get(api_url, headers=headers, timeout=10)
        return response.status_code == 200
    except:
        return False

# ูุงุฌูุฉ ุงูุชุทุจูู
st.title("๐ ูููุฏ ุงูุฃุณุฆูุฉ ุงููุชููุนุฉ ูู ูููุงุช PDF")
st.markdown("ุงุฑูุน ููู PDF ูุงุฎุชุฑ ูุทุงู ุงูุตูุญุงุช ูุฃููุงุน ุงูุฃุณุฆูุฉ ุงูุชู ุชุฑูุฏ ุชูููุฏูุง")

# ุนุฑุถ ูุนูููุงุช ุงูู Token
if API_TOKEN:
    st.success("โ ุชู ุงูุนุซูุฑ ุนูู API Token")
else:
    st.error("โ ูู ูุชู ุฅุฏุฎุงู API Token")

uploaded_file = st.file_uploader(
    "ุงุฑูุน ููู PDF", 
    type=["pdf"],
    help="ุญุฏ ุฃูุตู: 200MB"
)

if uploaded_file is not None and API_TOKEN:
    # ุงุณุชุฎุฑุงุฌ ูุนูููุงุช ุฃุณุงุณูุฉ ุนู ุงูููู
    try:
        pdf = PdfReader(uploaded_file)
        total_pages = len(pdf.pages)
        
        st.success(f"โ ุชู ุฑูุน ุงูููู ุจูุฌุงุญ! ุนุฏุฏ ุงูุตูุญุงุช: {total_pages}")
        
        # ุงุฎุชูุงุฑ ุงููููุฐุฌ ูุน ุงูุชุญูู ูู ุงูุญุงูุฉ
        st.subheader("๐ค ุงุฎุชุฑ ุงููููุฐุฌ:")
        selected_model = st.selectbox(
            "ุงููููุฐุฌ ุงููุณุชุฎุฏู:",
            options=list(ARABIC_MODELS.keys()),
            format_func=lambda x: ARABIC_MODELS[x],
            help="ุงุฎุชุฑ ุงููููุฐุฌ ุงูุฃูุณุจ ูุชูููุฏ ุงูุฃุณุฆูุฉ"
        )
        
        # ุงูุชุญูู ูู ุญุงูุฉ ุงููููุฐุฌ
        with st.spinner("๐ ุฌุงุฑู ุงูุชุญูู ูู ุญุงูุฉ ุงููููุฐุฌ..."):
            model_available = check_model_status(selected_model, API_TOKEN)
            
        if model_available:
            st.success(f"โ ุงููููุฐุฌ {ARABIC_MODELS[selected_model]} ูุชุงุญ ููุนูู")
        else:
            st.warning(f"โ๏ธ ุงููููุฐุฌ ูุฏ ูููู ุบูุฑ ูุชุงุญ ุญุงููุงูุ ุณูุชู ุงุณุชุฎุฏุงู ุงูุฃุณุฆูุฉ ุงูุงูุชุฑุงุถูุฉ")
        
        # ุฎูุงุฑุงุช ูุทุงู ุงูุตูุญุงุช ูุน ุงูููู ุงูุงูุชุฑุงุถูุฉ ุงููุญุฏุซุฉ
        st.subheader("๐ ุงุฎุชุฑ ูุทุงู ุงูุตูุญุงุช:")
        
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            start_page = st.number_input(
                "ุงูุตูุญุฉ ุงูุฃููู:", 
                min_value=1, 
                max_value=total_pages, 
                value=1,
                help=f"ุงุฎุชุฑ ูู 1 ุฅูู {total_pages}"
            )
        
        with col2:
            end_page = st.number_input(
                "ุงูุตูุญุฉ ุงูุฃุฎูุฑุฉ:", 
                min_value=1, 
                max_value=total_pages, 
                value=total_pages,
                help=f"ุงุฎุชุฑ ูู 1 ุฅูู {total_pages}"
            )
        
        with col3:
            if start_page > end_page:
                st.error("โ๏ธ ุงูุตูุญุฉ ุงูุฃููู ูุฌุจ ุฃู ุชููู ุฃูู ูู ุฃู ุชุณุงูู ุงูุตูุญุฉ ุงูุฃุฎูุฑุฉ")
            else:
                pages_count = end_page - start_page + 1
                st.info(f"๐ ุณูุชู ูุนุงูุฌุฉ {pages_count} ุตูุญุฉ")
        
        # ุงุฎุชูุงุฑ ุฃููุงุน ุงูุฃุณุฆูุฉ
        st.subheader("๐ ุงุฎุชุฑ ุฃููุงุน ุงูุฃุณุฆูุฉ:")
        question_types = st.multiselect(
            "ุฃููุงุน ุงูุฃุณุฆูุฉ ุงููุทููุจุฉ:",
            options=["ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ", "ุตุญ ุฃู ุฎุทุฃ", "ูุทุงุจูุฉ", "ูููุงุช ูุชูุงุทุนุฉ"],
            default=["ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ", "ุตุญ ุฃู ุฎุทุฃ"],
            help="ุงุฎุชุฑ ููุน ูุงุญุฏ ุฃู ุฃูุซุฑ ูู ุฃููุงุน ุงูุฃุณุฆูุฉ"
        )
        
        if not question_types:
            st.warning("โ๏ธ ูุฑุฌู ุงุฎุชูุงุฑ ููุน ูุงุญุฏ ุนูู ุงูุฃูู ูู ุฃููุงุน ุงูุฃุณุฆูุฉ")
        
        if start_page <= end_page and question_types:
            # ุงูุฃุฒุฑุงุฑ
            col1, col2 = st.columns(2)
            
            with col1:
                preview_btn = st.button("๐๏ธ ูุนุงููุฉ ุงููุต ุงููุณุชุฎุฑุฌ", use_container_width=True)
            
            with col2:
                generate_btn = st.button("๐ค ุชูููุฏ ุงูุฃุณุฆูุฉ ุงูููุธูุฉ", type="primary", use_container_width=True)
            
            # ูุนุงููุฉ ุงููุต
            if preview_btn:
                with st.spinner("๐ ุฌุงุฑู ุงุณุชุฎุฑุงุฌ ุงููุต..."):
                    extracted_text, _, error = extract_text_from_pages(uploaded_file, start_page, end_page)
                    
                    if error:
                        st.error(f"โ ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุงุณุชุฎุฑุงุฌ ุงููุต: {error}")
                    elif extracted_text:
                        st.subheader("๐ ุงููุต ุงููุณุชุฎุฑุฌ:")
                        st.text_area(
                            f"ุงููุต ูู ุงูุตูุญุงุช {start_page}-{end_page}:", 
                            extracted_text, 
                            height=400,
                            help="ุฑุงุฌุน ุงููุต ูุจู ุชูููุฏ ุงูุฃุณุฆูุฉ"
                        )
                        
                        # ุญูุธ ุงููุต ูู session state
                        st.session_state.extracted_text = extracted_text
                        st.session_state.page_range = f"{start_page}-{end_page}"
                        
                        # ุฅุญุตุงุฆูุงุช ุงููุต
                        word_count = len(extracted_text.split())
                        char_count = len(extracted_text)
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("๐ ุนุฏุฏ ุงููููุงุช", word_count)
                        with col2:
                            st.metric("๐ ุนุฏุฏ ุงูุฃุญุฑู", char_count)
                        with col3:
                            st.metric("๐ ุนุฏุฏ ุงูุตูุญุงุช", pages_count)
                    else:
                        st.warning("โ๏ธ ูู ูุชู ุงูุนุซูุฑ ุนูู ูุต ูู ุงูุตูุญุงุช ุงููุญุฏุฏุฉ")
            
            # ุชูููุฏ ุงูุฃุณุฆูุฉ
            if generate_btn:
                import datetime
                st.session_state.generation_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                with st.spinner("๐ ุฌุงุฑู ุงุณุชุฎุฑุงุฌ ุงููุต ูุชูููุฏ ุงูุฃุณุฆูุฉ ุงูููุธูุฉ..."):
                    # ุงุณุชุฎุฑุงุฌ ุงููุต
                    extracted_text, _, error = extract_text_from_pages(uploaded_file, start_page, end_page)
                    
                    if error:
                        st.error(f"โ ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุงุณุชุฎุฑุงุฌ ุงููุต: {error}")
                    elif extracted_text:
                        # ูุญุงููุฉ ุชูููุฏ ุงูุฃุณุฆูุฉ ุจุงุณุชุฎุฏุงู API
                        api_success = False
                        if model_available:
                            with st.spinner(f"๐ค ุฌุงุฑู ุชูููุฏ ุงูุฃุณุฆูุฉ ุจุงุณุชุฎุฏุงู {ARABIC_MODELS[selected_model]}..."):
                                result = generate_questions(extracted_text, API_TOKEN, question_types, selected_model)
                                
                                if isinstance(result, dict) and "error" not in result:
                                    api_success = True
                                    st.success("โ ุชู ุชูููุฏ ุงูุฃุณุฆูุฉ ุจูุงุณุทุฉ AI ุจูุฌุงุญ!")
                                    
                                    # ูุนุงูุฌุฉ ุงุณุชุฌุงุจุฉ API
                                    if isinstance(result, list) and len(result) > 0:
                                        questions = result[0].get
