import os
import streamlit as st
from PyPDF2 import PdfReader
import requests

# Ù‚Ø±Ø§Ø¡Ø© Ø±Ù…Ø² API Ù…Ù† Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©
API_TOKEN = os.getenv("API_TOKEN")

# Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©ØŒ Ø§Ø·Ù„Ø¨Ù‡ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
if not API_TOKEN:
    st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ API Token ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚")
    API_TOKEN = st.text_input(
        "Ø£Ø¯Ø®Ù„ Hugging Face API Token:", 
        type="password",
        help="Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù€ Token Ù…Ù† huggingface.co/settings/tokens"
    )
    
    if not API_TOKEN:
        st.info("ğŸ’¡ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Token Ù…Ø¬Ø§Ù†ÙŠ Ù…Ù†: https://huggingface.co/settings/tokens")
        st.stop()

# Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Hugging Face
def generate_questions(text, api_token):
    headers = {"Authorization": f"Bearer {api_token}"}
    
    # Ù†Ù…ÙˆØ°Ø¬ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    api_url = "https://api-inference.huggingface.co/models/aubmindlab/bert-base-arabertv02"
    
    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù†Øµ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
    prompt = f"Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠØŒ Ù‚Ù… Ø¨ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ù…ÙÙŠØ¯Ø©:\n\n{text[:2000]}..."  # ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ
    payload = {"inputs": prompt}
    
    try:
        response = requests.post(api_url, headers=headers, json=payload, timeout=30)
        if response.status_code == 200:
            return response.json()
        else:
            return {"error": f"API request failed with status {response.status_code}: {response.text}"}
    except requests.exceptions.RequestException as e:
        return {"error": f"Request failed: {str(e)}"}

# Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù†Ø·Ø§Ù‚ ØµÙØ­Ø§Øª Ù…Ø­Ø¯Ø¯
def extract_text_from_pages(pdf_file, start_page, end_page):
    full_text = ""
    try:
        pdf = PdfReader(pdf_file)
        total_pages = len(pdf.pages)
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª
        start_page = max(1, min(start_page, total_pages))
        end_page = max(start_page, min(end_page, total_pages))
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
        for page_num in range(start_page - 1, end_page):
            page = pdf.pages[page_num]
            text = page.extract_text()
            if text:
                full_text += f"--- ØµÙØ­Ø© {page_num + 1} ---\n{text}\n\n"
        
        return full_text, total_pages, None
    except Exception as e:
        return "", 0, str(e)

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.set_page_config(
    page_title="Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† PDF",
    page_icon="ğŸ“š",
    layout="wide"
)

st.title("ğŸ“š Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ù…Ù„ÙØ§Øª PDF")
st.markdown("Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF ÙˆØ§Ø®ØªØ± Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ ØªÙˆÙ„ÙŠØ¯ Ø£Ø³Ø¦Ù„Ø© Ù…Ù†Ù‡Ø§")

# Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù€ Token
if API_TOKEN:
    st.success("âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ API Token")
else:
    st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø¥Ø¯Ø®Ø§Ù„ API Token")

uploaded_file = st.file_uploader(
    "Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF", 
    type=["pdf"],
    help="Ø­Ø¯ Ø£Ù‚ØµÙ‰: 200MB"
)

if uploaded_file is not None and API_TOKEN:
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© Ø¹Ù† Ø§Ù„Ù…Ù„Ù
    try:
        pdf = PdfReader(uploaded_file)
        total_pages = len(pdf.pages)
        
        st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­! Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª: {total_pages}")
        
        # Ø®ÙŠØ§Ø±Ø§Øª Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª
        st.subheader("ğŸ”– Ø§Ø®ØªØ± Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª:")
        
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            start_page = st.number_input(
                "Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰:", 
                min_value=1, 
                max_value=total_pages, 
                value=1,
                help=f"Ø§Ø®ØªØ± Ù…Ù† 1 Ø¥Ù„Ù‰ {total_pages}"
            )
        
        with col2:
            end_page = st.number_input(
                "Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©:", 
                min_value=1, 
                max_value=total_pages, 
                value=min(3, total_pages),  # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ Ø£ÙˆÙ„ 3 ØµÙØ­Ø§Øª
                help=f"Ø§Ø®ØªØ± Ù…Ù† 1 Ø¥Ù„Ù‰ {total_pages}"
            )
        
        with col3:
            if start_page > end_page:
                st.error("âš ï¸ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø£Ù‚Ù„ Ù…Ù† Ø£Ùˆ ØªØ³Ø§ÙˆÙŠ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©")
            else:
                pages_count = end_page - start_page + 1
                st.info(f"ğŸ“„ Ø³ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© {pages_count} ØµÙØ­Ø©")
        
        if start_page <= end_page:
            # Ø§Ù„Ø£Ø²Ø±Ø§Ø±
            col1, col2 = st.columns(2)
            
            with col1:
                preview_btn = st.button("ğŸ‘ï¸ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬", use_container_width=True)
            
            with col2:
                generate_btn = st.button("ğŸ¤– ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", type="primary", use_container_width=True)
            
            # Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù†Øµ
            if preview_btn:
                with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ..."):
                    extracted_text, _, error = extract_text_from_pages(uploaded_file, start_page, end_page)
                    
                    if error:
                        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {error}")
                    elif extracted_text:
                        st.subheader("ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:")
                        st.text_area(
                            f"Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙØ­Ø§Øª {start_page}-{end_page}:", 
                            extracted_text, 
                            height=400,
                            help="Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù†Øµ Ù‚Ø¨Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"
                        )
                        
                        # Ø­ÙØ¸ Ø§Ù„Ù†Øµ ÙÙŠ session state
                        st.session_state.extracted_text = extracted_text
                        st.session_state.page_range = f"{start_page}-{end_page}"
                        
                        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Øµ
                        word_count = len(extracted_text.split())
                        char_count = len(extracted_text)
                        st.metric("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Øµ", f"{word_count} ÙƒÙ„Ù…Ø©ØŒ {char_count} Ø­Ø±Ù")
                    else:
                        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ ÙÙŠ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©")
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
            if generate_btn:
                with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©..."):
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
                    extracted_text, _, error = extract_text_from_pages(uploaded_file, start_page, end_page)
                    
                    if error:
                        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {error}")
                    elif extracted_text:
                        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
                        with st.spinner
